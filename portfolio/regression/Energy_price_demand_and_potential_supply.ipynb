{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitaliy-sharandin/data_science_projects/blob/master/portfolio/regression/Energy_price_demand_and_potential_supply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Energy demand prediction of Spain's major cities\n",
        "\n",
        "This project uses energy demand information from major Spanish cities to predict cumulative energy consumption."
      ],
      "metadata": {
        "id": "5g5sn0fed2SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "Spanish major cities energy consumption and weather dataset\n",
        "* https://www.kaggle.com/datasets/nicholasjhana/energy-consumption-generation-prices-and-weather\n",
        "\n"
      ],
      "metadata": {
        "id": "vrrnzKooh7uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q datasets\n",
        "!pip install -U -q ydata-profiling\n",
        "!pip install -U -q feature_engine\n",
        "!pip install -U -q Boruta\n",
        "!pip install -U -q optuna\n",
        "!pip install -U -q eli5\n",
        "!pip install statsforecast"
      ],
      "metadata": {
        "id": "cipdnuo5bq8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA\n"
      ],
      "metadata": {
        "id": "AemoxCzzBtDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from ydata_profiling import ProfileReport\n",
        "import pandas as pd\n",
        "from feature_engine.encoding import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from boruta import BorutaPy\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
      ],
      "metadata": {
        "id": "VR-5zkUkNZk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlNrYf_87VRa"
      },
      "outputs": [],
      "source": [
        "energy_consumption_dataset = load_dataset(\"vitaliy-sharandin/energy-consumption-hourly-spain\")\n",
        "energy_consumption_weather_dataset = load_dataset(\"vitaliy-sharandin/energy-consumption-weather-hourly-spain\")\n",
        "energy_df = energy_consumption_dataset['train'].to_pandas()\n",
        "weather_df = energy_consumption_weather_dataset['train'].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Energy dataset"
      ],
      "metadata": {
        "id": "ZKvWZvBF-NPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df['time'] = pd.to_datetime(energy_df['time'], errors=\"coerce\", utc=True)\n",
        "energy_df = energy_df.set_index('time')\n",
        "energy_df.index = pd.to_datetime(energy_df.index,utc=True)\n",
        "energy_df=energy_df.asfreq('h')"
      ],
      "metadata": {
        "id": "X_BFfmUWhtcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# profile = ProfileReport(energy_df, title=\"Energy data report\", dark_mode=True)\n",
        "# profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "QTxMV4tJsNEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df.drop(['generation hydro pumped storage aggregated','forecast wind offshore eday ahead',\n",
        "                'generation marine','generation fossil coal-derived gas','generation fossil oil shale',\n",
        "                'generation fossil peat','generation geothermal','generation marine','generation wind offshore'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "dqrhcrn9x2u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_variables(target, df_train, cat_numeric_unique_threshold=10):\n",
        "  target = target\n",
        "  categorical_numeric = [var for var in df_train.columns if df_train[var].dtype!='O' and var!=target and df_train[var].nunique()<=cat_numeric_unique_threshold]\n",
        "  continuous = [var for var in df_train.columns if df_train[var].dtype!='O' and var!=target and var not in categorical_numeric]\n",
        "  mixed = [var for var in df_train.columns if pd.api.types.infer_dtype(df_train[var]) == 'mixed']\n",
        "  categorical_object = [var for var in df_train.columns if df_train[var].dtype=='O' and var not in mixed]\n",
        "  sorted_features = [target]+categorical_numeric+continuous+categorical_object+mixed\n",
        "  print('Total columns: '+str(df_train.columns.size)+'\\nColumns after sorting: '+str(len(sorted_features)))\n",
        "  return target, categorical_numeric, continuous, mixed, categorical_object\n",
        "target, categorical_numeric, continuous, mixed, categorical_object = categorize_variables('total load actual', energy_df)"
      ],
      "metadata": {
        "id": "X8NyxaF2O1Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df[categorical_numeric+continuous]=energy_df[categorical_numeric+continuous].fillna(energy_df[categorical_numeric+continuous].mean())\n",
        "energy_df[target] = energy_df[target].interpolate(method='linear')"
      ],
      "metadata": {
        "id": "OihuQfc_i8gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "* Some features were highly correlated, but we'll deal with them in feature selection phase.\n",
        "* 2 features were completely missing and 6 were constant, so we dropped them.\n",
        "* Categorical variables were filled with mean values.\n",
        "* Target variable had several missing values as well, so we used linear interpolation to fill them."
      ],
      "metadata": {
        "id": "wohg6kFdzlRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target variable analysis"
      ],
      "metadata": {
        "id": "vi9067oCoUCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_decompose = seasonal_decompose(energy_df[:168][target], model='additive')\n",
        "plot = target_decompose.plot()\n",
        "plot.set_size_inches((16, 9))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0sNIQoCTWVQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acf(energy_df[target], lags=5)\n",
        "plt.show()\n",
        "plot_pacf(energy_df[target], lags=5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s_laQ7-TqCIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "* Series are non-stationary.\n",
        "* Target variable has daily seasonality.\n",
        "* The dataset has properties of AR process what stems from fast cutoff in PACF chart, this will become handy when we test ARIMA based models."
      ],
      "metadata": {
        "id": "JHVMaPrUPp59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weather dataset EDA"
      ],
      "metadata": {
        "id": "0Lx7GIkS9qa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df['dt_iso'] = pd.to_datetime(weather_df['dt_iso'], utc=True)"
      ],
      "metadata": {
        "id": "POGSbAnAFtKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# profile = ProfileReport(weather_df, title=\"Weather data report\")\n",
        "# profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "XVHn5xKQN460"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df.drop(['rain_3h','weather_main','weather_icon'], axis=1, inplace=True)\n",
        "weather_df = weather_df[weather_df['dt_iso'].isin(energy_df.index) & (~weather_df.duplicated(['dt_iso','city_name']))]"
      ],
      "metadata": {
        "id": "pmHKSqzXdBsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = weather_df.set_index(['dt_iso','city_name'])\n",
        "weather_df = weather_df.unstack('city_name')\n",
        "weather_df.columns = ['_'.join(col).strip() for col in weather_df.columns.values]"
      ],
      "metadata": {
        "id": "iqnZmWzDzixd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merging energy and weather dataset"
      ],
      "metadata": {
        "id": "HuxAgotD9723"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "energy_weather_df = energy_df.join(weather_df, how='inner')"
      ],
      "metadata": {
        "id": "6u7WPZ5X-rM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection and engineering"
      ],
      "metadata": {
        "id": "olSkAVtoVRbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming variables"
      ],
      "metadata": {
        "id": "s0dnHMbZ-lUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target, categorical_numeric, continuous, mixed, categorical_object = categorize_variables('total load actual', energy_weather_df)\n",
        "\n",
        "train = energy_weather_df[:-168]\n",
        "test = energy_weather_df[-168:]\n",
        "\n",
        "encoder = OrdinalEncoder(\n",
        "    variables=categorical_object,\n",
        "    encoding_method='ordered'\n",
        ")\n",
        "\n",
        "train = encoder.fit_transform(train, train[target])\n",
        "test = encoder.fit_transform(test, test[target])"
      ],
      "metadata": {
        "id": "Eb98HwEgR7pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature selection"
      ],
      "metadata": {
        "id": "2Ea8uIrA-p85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "import eli5\n",
        "\n",
        "# params = {\n",
        "#     'objective': 'reg:squarederror',\n",
        "#     'random_state': 42,\n",
        "#     'n_jobs': -1,\n",
        "#     'learning_rate': 0.1,\n",
        "#     'max_depth': 3,\n",
        "#     'min_child_weight': 1,\n",
        "#     'gamma': 0,\n",
        "#     'subsample': 0.8,\n",
        "#     'colsample_bytree': 0.8,\n",
        "#     'reg_alpha': 0,\n",
        "#     'reg_lambda': 1\n",
        "# }\n",
        "\n",
        "xgb = XGBRegressor()\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "display(eli5.show_weights(xgb, feature_names = X_test.columns.tolist()))"
      ],
      "metadata": {
        "id": "v0x5DhLlhJ6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# lgb_regressor = lgb.LGBMRegressor()\n",
        "\n",
        "# feat_selector = BorutaPy(lgb_regressor, n_estimators='auto', random_state=42)\n",
        "# feat_selector.fit(X_train.values, y_train.values)\n",
        "# selected_rf_features = pd.DataFrame({'Feature':list(X_train.columns),\n",
        "#                                        'Ranking':feat_selector.ranking_}).sort_values(by='Ranking')\n",
        "# selected_rf_features.nsmallest(40, 'Ranking').plot.barh(x='Feature',figsize=(24,5))"
      ],
      "metadata": {
        "id": "8DsMlDoRXCsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# black_list_features = ['generation biomass', 'generation fossil brown coal/lignite',\n",
        "#        'generation fossil gas', 'generation fossil hard coal',\n",
        "#        'generation fossil oil', 'generation hydro pumped storage consumption',\n",
        "#        'generation hydro run-of-river and poundage',\n",
        "#        'generation hydro water reservoir', 'generation nuclear',\n",
        "#        'generation other', 'generation other renewable', 'generation solar',\n",
        "#        'generation waste', 'generation wind onshore','forecast solar day ahead',\n",
        "#        'forecast wind onshore day ahead', 'price actual']\n",
        "\n",
        "# energy_weather_df = energy_weather_df[energy_weather_df.columns.difference(black_list_features)]"
      ],
      "metadata": {
        "id": "5UAEUJ2c38_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection"
      ],
      "metadata": {
        "id": "YqHfxOvM5xnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ARIMA and others with statsforecast model test"
      ],
      "metadata": {
        "id": "bBTrSAQZPnRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we transform data into statsforecast format and also order columns for statsforecast framework so that it can use"
      ],
      "metadata": {
        "id": "wcGNH7lv6Bgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_statsforecast_format(df):\n",
        "  energy_weather_df_forecast = df.copy()\n",
        "  energy_weather_df_forecast['unique_id'] = 'Energy_weather_Spain'\n",
        "  energy_weather_df_forecast['ds'] = energy_weather_df_forecast.index.tz_localize(None)\n",
        "  energy_weather_df_forecast = energy_weather_df_forecast.rename(columns={'total load actual':'y'})\n",
        "\n",
        "  exogenous_variables = energy_weather_df_forecast.columns.difference(['unique_id', 'ds', 'y']).tolist()\n",
        "  cols = ['unique_id', 'ds', 'y'] + exogenous_variables\n",
        "  return energy_weather_df_forecast.reindex(columns=cols)\n",
        "train = transform_to_statsforecast_format(train)\n",
        "test = transform_to_statsforecast_format(test)"
      ],
      "metadata": {
        "id": "P88MHBv46A4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's see how ARIMA, ETS, Theta and CES models behave."
      ],
      "metadata": {
        "id": "xE1rwIfebamk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import AutoARIMA\n",
        "\n",
        "season_length = 24\n",
        "prediction_horizon = 168\n",
        "\n",
        "\n",
        "models = [\n",
        "    AutoARIMA(season_length=season_length)\n",
        "]\n",
        "\n",
        "sf = StatsForecast(\n",
        "    models=models,\n",
        "    freq='H',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "fcst = sf.forecast(df=train, h=prediction_horizon, X_df=test[test.columns.difference(['y'])], level=[95])\n",
        "fcst = fcst.reset_index()\n",
        "display(fcst.head())\n",
        "StatsForecast.plot(test['y'], fcst, max_insample_length=28*2, engine='plotly')"
      ],
      "metadata": {
        "id": "I4tQyFHlt2XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pmdarima\n",
        "# import pmdarima as pm\n",
        "# SARIMAX_model = pm.auto_arima(y_train[-8760:], X=X_train[-8760:],\n",
        "#                            start_p=1, start_q=0,\n",
        "#                            start_P=1, start_Q=0,\n",
        "#                            test='adf',\n",
        "#                            max_p=2, max_q=0,\n",
        "#                            max_P=2, max_Q=0,\n",
        "#                            m=24,\n",
        "#                            seasonal=True,\n",
        "#                            stepwise=True,\n",
        "#                            trace=True,\n",
        "#                            maxiter=10)\n",
        "\n",
        "# def sarimax_forecast(SARIMAX_model, periods):\n",
        "#     # Forecast\n",
        "#     n_periods = periods\n",
        "\n",
        "#     predicted, confint = SARIMAX_model.predict(n_periods=n_periods,\n",
        "#                                             return_conf_int=True)\n",
        "#     index_of_fc = predicted.index\n",
        "\n",
        "#     # make series for plotting purpose\n",
        "#     predicted_series = pd.Series(predicted, index=index_of_fc)\n",
        "#     lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
        "#     upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
        "\n",
        "#     # Plot\n",
        "#     plt.figure(figsize=(15,7))\n",
        "#     plt.plot(y_test, color='#1f76b4')\n",
        "#     plt.plot(predicted_series, color='darkgreen')\n",
        "#     plt.fill_between(lower_series.index,\n",
        "#                     lower_series,\n",
        "#                     upper_series,\n",
        "#                     color='k', alpha=.15)\n",
        "\n",
        "#     plt.title(\"SARIMAX Forecast\")\n",
        "#     plt.show()\n",
        "\n",
        "# sarimax_forecast(SARIMAX_model, periods=168)"
      ],
      "metadata": {
        "id": "6zfoxy5cbLYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, SARIMAX model did not perform well"
      ],
      "metadata": {
        "id": "DxI6d-barMJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree and Deep learning model tests with MLForecast framework"
      ],
      "metadata": {
        "id": "9XOMVVsaOU5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q mlforecast\n",
        "!pip install -U -q neuralforecast\n",
        "!pip install -U -q datasetsforecast\n",
        "!pip install -U -q pmdarima"
      ],
      "metadata": {
        "id": "yJeat3uROTTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlforecast import MLForecast\n",
        "from datasetsforecast.losses import rmse\n",
        "import pmdarima as pm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import LSTM\n",
        "from neuralforecast.losses.pytorch import DistributionLoss"
      ],
      "metadata": {
        "id": "ytHXZY5lv0Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing dataset in MLForecast format"
      ],
      "metadata": {
        "id": "AHIvOPP7MNVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "energy_weather_df_mlforecast = energy_weather_df.copy()\n",
        "energy_weather_df_mlforecast['unique_id'] = 'Energy_weather_Spain'\n",
        "energy_weather_df_mlforecast['ds'] = energy_weather_df_mlforecast.index.tz_localize(None)\n",
        "energy_weather_df_mlforecast = energy_weather_df_mlforecast.rename(columns={'total load actual':'y'})"
      ],
      "metadata": {
        "id": "HirrwxjVPL0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = energy_weather_df_mlforecast[:-168]\n",
        "test = energy_weather_df_mlforecast[-168:]\n",
        "\n",
        "encoder = OrdinalEncoder(\n",
        "    variables=categorical_object,\n",
        "    encoding_method='ordered'\n",
        ")\n",
        "\n",
        "train = encoder.fit_transform(train, train['y'])\n",
        "test = encoder.fit_transform(test, test['y'])"
      ],
      "metadata": {
        "id": "MscvG_riltAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree model hyperparameters search"
      ],
      "metadata": {
        "id": "1G6oOR69MMLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# def objective(trial):\n",
        "\n",
        "#     model_name = trial.suggest_categorical(\"classifier\", ['LGBMRegressor', 'XGBRegressor'])\n",
        "\n",
        "#     if model_name == \"LGBMRegressor\":\n",
        "#       params = {\n",
        "#         \"objective\": \"regression\",\n",
        "#         \"metric\": \"rmse\",\n",
        "#         \"n_estimators\": 1000,\n",
        "#         \"verbosity\": -1,\n",
        "#         \"bagging_freq\": 1,\n",
        "#         \"learning_rate\": trial.suggest_float(\"learning_rate_light\", 1e-3, 0.1, log=True),\n",
        "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
        "#         \"subsample\": trial.suggest_float(\"subsample_light\", 0.05, 1.0),\n",
        "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree_light\", 0.05, 1.0),\n",
        "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "#       }\n",
        "#       model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "#     elif model_name == \"XGBRegressor\":\n",
        "#       params = {\n",
        "#       'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
        "#       'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
        "#       'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "#       'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "#       'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "#       'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
        "#       'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
        "#       'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
        "#       'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
        "#       'eval_metric': 'rmse',\n",
        "#       'use_label_encoder': False\n",
        "#       }\n",
        "#       model = xgb.XGBRegressor(**params)\n",
        "\n",
        "#     ml_forecast = MLForecast(models=[model],\n",
        "#                    freq='H',\n",
        "#                    lags=[1,2,12,24,168],\n",
        "#                    date_features=['hour','day','week', 'month'],\n",
        "#                    num_threads=6)\n",
        "\n",
        "#     crossvalidation_df = ml_forecast.cross_validation(\n",
        "#                                                       data=train,\n",
        "#                                                       window_size=168,\n",
        "#                                                       n_windows=3,\n",
        "#                                                     )\n",
        "#     rmse = crossvalidation_df.groupby(['unique_id', 'cutoff']).apply(lambda df: rmse(df['y'], df[model_name])).mean()\n",
        "\n",
        "#     return rmse\n",
        "\n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "# display(study.best_params)\n",
        "# display(study.best_value)"
      ],
      "metadata": {
        "id": "CkGOl4aEk130"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing tree models"
      ],
      "metadata": {
        "id": "egkR7k_-MfEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_forecast = MLForecast(models=[model],\n",
        "#                    freq='H',\n",
        "#                    lags=[1,2,3,12,24],\n",
        "#                    date_features=['hour','day','week'],\n",
        "#                    num_threads=6)\n",
        "\n",
        "# ml_forecast.fit(train, target_col='y')\n",
        "# y_pred = ml_forecast.predict(len(test.index))\n",
        "\n",
        "# for model_name in ml_forecast.models:\n",
        "#   display(mean_squared_error(test['y'], y_pred[model_name], squared=False))\n",
        "\n",
        "#   pd.Series(ml_forecast.models_[model_name].feature_importances_, index=ml_forecast.ts.features_order_).sort_values(ascending=False).plot.bar(figsize=(32, 6),title=f'{model_name} feature importance')\n",
        "#   plt.show()\n",
        "\n",
        "#   plt.figure(figsize=(30, 6))\n",
        "#   sns.lineplot(x=test.index, y=test['y'], label='Real')\n",
        "#   sns.lineplot(x=test.index, y=y_pred[model_name], label='Predicted')\n",
        "#   plt.title('Real vs Predicted Values')\n",
        "#   plt.legend()\n",
        "#   plt.show()"
      ],
      "metadata": {
        "id": "8CEoZH4GRVjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL model hyperparameter search"
      ],
      "metadata": {
        "id": "sT3dDeLWYY7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# def objective(trial):\n",
        "\n",
        "#     model_name = trial.suggest_categorical(\"classifier\", ['LGBMRegressor', 'XGBRegressor'])\n",
        "\n",
        "#     if model_name == \"LGBMRegressor\":\n",
        "#       params = {\n",
        "#         \"objective\": \"regression\",\n",
        "#         \"metric\": \"rmse\",\n",
        "#         \"n_estimators\": 1000,\n",
        "#         \"verbosity\": -1,\n",
        "#         \"bagging_freq\": 1,\n",
        "#         \"learning_rate\": trial.suggest_float(\"learning_rate_light\", 1e-3, 0.1, log=True),\n",
        "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
        "#         \"subsample\": trial.suggest_float(\"subsample_light\", 0.05, 1.0),\n",
        "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree_light\", 0.05, 1.0),\n",
        "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "#       }\n",
        "#       model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "#     elif model_name == \"XGBRegressor\":\n",
        "#       params = {\n",
        "#       'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
        "#       'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
        "#       'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "#       'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "#       'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "#       'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
        "#       'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
        "#       'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
        "#       'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
        "#       'eval_metric': 'rmse',\n",
        "#       'use_label_encoder': False\n",
        "#       }\n",
        "#       model = xgb.XGBRegressor(**params)\n",
        "\n",
        "#     ml_forecast = MLForecast(models=[model],\n",
        "#                    freq='H',\n",
        "#                    lags=[1,2,12,24,168],\n",
        "#                    date_features=['hour','day','week', 'month'],\n",
        "#                    num_threads=6)\n",
        "\n",
        "#     crossvalidation_df = ml_forecast.cross_validation(\n",
        "#                                                       data=train,\n",
        "#                                                       window_size=168,\n",
        "#                                                       n_windows=3,\n",
        "#                                                     )\n",
        "#     rmse = crossvalidation_df.groupby(['unique_id', 'cutoff']).apply(lambda df: rmse(df['y'], df[model_name])).mean()\n",
        "\n",
        "#     return rmse\n",
        "\n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "# display(study.best_params)\n",
        "# display(study.best_value)"
      ],
      "metadata": {
        "id": "SZO1Tk8nYUSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL model testing"
      ],
      "metadata": {
        "id": "xrrmjltkVGDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, gc\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\"\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "bXCyMnOdkH1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_horizon = 168\n",
        "\n",
        "models = [LSTM(h=prediction_horizon,\n",
        "               loss=DistributionLoss(distribution='Normal', level=[90]),\n",
        "               max_steps=50,\n",
        "               encoder_n_layers=2,\n",
        "               encoder_hidden_size=200,\n",
        "               context_size=8760,\n",
        "               decoder_hidden_size=200,\n",
        "               decoder_layers=2,\n",
        "               learning_rate=1e-3,\n",
        "               scaler_type='standard',\n",
        "               futr_exog_list=['onpromotion'])]\n",
        "\n",
        "neural_forecast = NeuralForecast(models=models, freq='H')\n",
        "neural_forecast.fit(train)\n",
        "\n",
        "y_pred = neural_forecast.predict(futr_df=test)\n",
        "\n",
        "for model_name in neural_forecast.models:\n",
        "  display(mean_squared_error(test['y'], y_pred[model_name], squared=False))\n",
        "\n",
        "  pd.Series(neural_forecast.models_[model_name].feature_importances_, index=neural_forecast.ts.features_order_).sort_values(ascending=False).plot.bar(figsize=(32, 6),title=f'{model_name} feature importance')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(30, 6))\n",
        "  sns.lineplot(x=test.index, y=test['y'], label='Real')\n",
        "  sns.lineplot(x=test.index, y=y_pred[model_name], label='Predicted')\n",
        "  plt.title('Real vs Predicted Values')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5tDj99QeVCJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred =  neural_forecast.predict(futr_df=test)\n",
        "\n",
        "for model_name in neural_forecast.models:\n",
        "  display(mean_squared_error(test['y'], y_pred[model_name], squared=False))\n",
        "\n",
        "  pd.Series(neural_forecast.models_[model_name].feature_importances_, index=neural_forecast.ts.features_order_).sort_values(ascending=False).plot.bar(figsize=(32, 6),title=f'{model_name} feature importance')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(30, 6))\n",
        "  sns.lineplot(x=test.index, y=test['y'], label='Real')\n",
        "  sns.lineplot(x=test.index, y=y_pred[model_name], label='Predicted')\n",
        "  plt.title('Real vs Predicted Values')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uz3L9tXjwekF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}