{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitaliy-sharandin/data_science_projects/blob/master/portfolio/nlp/fine-tuned-llm/psy_ai_wandb_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8fa5101a-1278-47c5-948a-fe224c089686",
          "showTitle": false,
          "title": ""
        },
        "id": "_xQyhsoXyO0K"
      },
      "source": [
        "# Psy AI\n",
        "Psy AI is a Llama3-8b model instruction fine-tuned on depression dataset and is meant to help improve mental well-being.\n",
        "\n",
        "In future iterations it is meant to be trained on multiple philosophical and psychological datasets in order to provide multifaceted answers to complex mental health issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6b4773ad-485c-4b64-a100-3ed5866a25ec",
          "showTitle": false,
          "title": ""
        },
        "id": "zk7zN_7jYMZr"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1f0f94a8-3eef-4793-804c-7419d014cfd8",
          "showTitle": false,
          "title": ""
        },
        "id": "cZ-ecgabMSzo"
      },
      "source": [
        "Philosophy datasets (* for future training)\n",
        "* https://www.kaggle.com/datasets/christopherlemke/philosophical-texts\n",
        "* https://www.workwithdata.com/object/philosophy-science-complete-a-text-on-traditional-problems-schools-thought-book-by-edwin-h-c-hung-0000\n",
        "* https://www.kaggle.com/datasets/christopherlemke/philosophy-authors-writings-german\n",
        "* https://www.workwithdata.com/object/philosophical-inquiries-an-introduction-to-problems-philosophy-book-by-nicholas-rescher-0000\n",
        "* https://www.workwithdata.com/object/roman-stoicism-book-by-edward-vernon-arnold-1857\n",
        "* https://www.workwithdata.com/object/wisdom-energy-basic-buddhist-teachings-book-by-thubten-yeshe-1935"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "500d53d1-738f-4476-890f-63b6f145bf03",
          "showTitle": false,
          "title": ""
        },
        "id": "bkTCPgfTLIZh"
      },
      "source": [
        "Psychology and mental health datasets\n",
        "\n",
        "* Kaggle Depression data for chatbot https://www.kaggle.com/datasets/nupurgopali/depression-data-for-chatbot\n",
        "* Kaggle Psychometrics dataset https://www.kaggle.com/discussions/general/304994\n",
        "* Psychometric tests dataset https://ieee-dataport.org/documents/psychometric-tests-dataset\n",
        "* Psychometric NLP https://paperswithcode.com/dataset/psychometric-nlp\n",
        "* Reddit mental health dataset https://zenodo.org/record/3941387\n",
        "* Reddit mental disorders identification https://www.kaggle.com/datasets/kamaruladha/mental-disorders-identification-reddit-nlp\n",
        "* Kaggle Mental Health Conversational Data https://www.kaggle.com/datasets/elvis23/mental-health-conversational-data\n",
        "* Kaggle Mental Health FAQ for Chatbot https://www.kaggle.com/narendrageek/mental-health-faq-for-chatbot/code\n",
        "* A human consciousness questionnaire dataset https://data.mendeley.com/datasets/69p62ksdh6\n",
        "* paperswithcode Self-reported Mental Health Diagnoses https://paperswithcode.com/dataset/smhd\n",
        "* paperswithcode Mental Health Summarization Dataset https://paperswithcode.com/dataset/mentsum\n",
        "* HuggingFace psychology dataset https://huggingface.co/datasets/samhog/psychology-10k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "993e2c33-e4d5-4a21-8aa6-62ab49226721",
          "showTitle": false,
          "title": ""
        },
        "id": "bGXegQDzNtru"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q gradio\n",
        "!pip install -U -q datasets\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U accelerate\n",
        "!pip install -U -q trl\n",
        "\n",
        "!pip install -U -q evaluate\n",
        "!pip install -U -q rouge_score\n",
        "!pip install -U -q optuna\n",
        "!pip install -U -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1ccc1208-e995-421e-a773-00f4b302f6cb",
          "showTitle": false,
          "title": ""
        },
        "id": "TKvdMbEluPVb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import yaml\n",
        "import gradio as gr\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import GenerationConfig, Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel, AutoPeftModelForCausalLM\n",
        "import numpy as np\n",
        "from evaluate import load\n",
        "import optuna\n",
        "import wandb\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7427406b-3d7a-4556-87c8-ad836ad8fcb7",
          "showTitle": false,
          "title": ""
        },
        "id": "iiHYVFJyQuS2"
      },
      "source": [
        "# Dataset instruction transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cbb2b618-5c57-400c-a2ed-6f0b7e60ff09",
          "showTitle": false,
          "title": ""
        },
        "id": "T-UWXlYqAErf"
      },
      "source": [
        "Depression dataset with 51 q&a entries was taken for mvp to see if model is indeed training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e62c7f46-6924-47a4-ab3a-2c107d73653d",
          "showTitle": false,
          "title": ""
        },
        "id": "LvA-W04yBvga"
      },
      "outputs": [],
      "source": [
        "depression_dataset = load_dataset(\"vitaliy-sharandin/depression-instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "14709b86-cf55-4279-9756-7aed943255fe",
          "showTitle": false,
          "title": ""
        },
        "id": "fhM-wT3iAtm1"
      },
      "source": [
        "First, we modify our dataset to Alpaca format and create two datasets. One - for testing and evaluation and second one for inference, where responses are not available in formatted prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9690b50f-2d3e-48a3-bca8-b0b6604673cd",
          "showTitle": false,
          "title": ""
        },
        "id": "hwGaZ5y5A53T"
      },
      "outputs": [],
      "source": [
        "def formatting_func_train(example):\n",
        "  if example.get(\"context\", \"\") != \"\":\n",
        "      input_prompt = (f\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      \"### Instruction:\\n\"\n",
        "      f\"{example['instruction']}\\n\\n\"\n",
        "      f\"### Input: \\n\"\n",
        "      f\"{example['context']}\\n\\n\"\n",
        "      f\"### Response: \\n\"\n",
        "      f\"{example['response']}\")\n",
        "\n",
        "  else:\n",
        "    input_prompt = (f\"Below is an instruction that describes a task. \"\n",
        "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      \"### Instruction:\\n\"\n",
        "      f\"{example['instruction']}\\n\\n\"\n",
        "      f\"### Response:\\n\"\n",
        "      f\"{example['response']}\")\n",
        "\n",
        "  return {\"text\" : input_prompt}\n",
        "\n",
        "def formatting_func_test(example):\n",
        "  if example.get(\"context\", \"\") != \"\":\n",
        "      input_prompt = (f\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      \"### Instruction:\\n\"\n",
        "      f\"{example['instruction']}\\n\\n\"\n",
        "      f\"### Input: \\n\"\n",
        "      f\"{example['context']}\\n\\n\"\n",
        "      f\"### Response: \\n\")\n",
        "\n",
        "  else:\n",
        "    input_prompt = (f\"Below is an instruction that describes a task. \"\n",
        "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      \"### Instruction:\\n\"\n",
        "      f\"{example['instruction']}\\n\\n\"\n",
        "      f\"### Response: \\n\")\n",
        "\n",
        "  return {\"text\" : input_prompt}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e4c7f4e9-04d8-4cdb-8a69-ddc81a30589c",
          "showTitle": false,
          "title": ""
        },
        "id": "riRBYQdGA7Mc"
      },
      "outputs": [],
      "source": [
        "formatted_depression_dataset_train = depression_dataset['train'].map(formatting_func_train)\n",
        "formatted_depression_dataset_test = depression_dataset['train'].map(formatting_func_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7c826500-d0c1-4710-ac72-3bc4caf88540",
          "showTitle": false,
          "title": ""
        },
        "id": "-JWMiV2MM98j"
      },
      "source": [
        "# Model load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "33d01c00-365a-41b2-af4f-2cece650074c",
          "showTitle": false,
          "title": ""
        },
        "id": "Y1PfT1wI42ky"
      },
      "source": [
        "We are loading our Llama2 model in 4bit quantized form as well as applying Lora for peft training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c6adb738-73d7-40c4-87c2-397ccad6211a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d86ed2157b8d4937be3bca87d94a791a",
            "9e4fc7b4a62545b1b9f7a92aee5d4f1d",
            "5568f5e9f99c46799bbfd304841cc5ee",
            "8c7726b2c6f3411a99c715db4283d75f",
            "9e7306c2036547f680a951e279f3cad3",
            "b780273471f144a48cea7b2d6ab7eedd",
            "a48c9c3c9a604f0ca7f07bffdb395668",
            "7bb16bf91be544729e49ee2c1a03762d",
            "a9000a1453d64757b87d1939d933138e",
            "8741ad72690a4c31b6cec6fa57234954",
            "519a41fb203242e7ba381f595046161e"
          ]
        },
        "id": "ysK6WLI_qs6m",
        "outputId": "6b507c2d-0c15-445d-9731-5175c20380fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d86ed2157b8d4937be3bca87d94a791a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): Embedding(128256, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaSdpaAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "              (rotary_emb): LlamaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm()\n",
            "            (post_attention_layernorm): LlamaRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "def get_tokenizer():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.padding_side = \"right\"\n",
        "  return tokenizer\n",
        "\n",
        "def get_model():\n",
        "\n",
        "\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "  )\n",
        "\n",
        "  qlora_config = LoraConfig(lora_alpha=16,\n",
        "                          lora_dropout=0.1,\n",
        "                          r=64,\n",
        "                          bias=\"none\",\n",
        "                          task_type=\"CAUSAL_LM\")\n",
        "\n",
        "  base_training_model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config=bnb_config,\n",
        "      device_map = {\"\": 0}\n",
        "  )\n",
        "\n",
        "  base_training_model.gradient_checkpointing_enable()\n",
        "\n",
        "  base_training_model = prepare_model_for_kbit_training(base_training_model)\n",
        "  base_training_model = get_peft_model(base_training_model, qlora_config)\n",
        "  return base_training_model.to('cuda')\n",
        "\n",
        "base_training_model = get_model()\n",
        "tokenizer = get_tokenizer()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "print(base_training_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e2592187-511e-4d5f-a338-9c8c796e1e56",
          "showTitle": false,
          "title": ""
        },
        "id": "C8z9BjCdYPuB"
      },
      "source": [
        "# Model instruction fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f76a6d93-cba3-4b7e-bfe6-e25aad98d96a",
          "showTitle": false,
          "title": ""
        },
        "id": "mzN1Xpmp21BG"
      },
      "source": [
        "Here we are defining inference function which returns bleu, rouge and f1 metrics after comparison of predicted and reference responses. My tests have shown that standard trainer `compute_metrics` method is quite inefficient and is not quite suitable for instruction fine-tuning during manual observations or generated results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "022438a6-8335-451d-ab12-885a2c9436e9",
          "showTitle": false,
          "title": ""
        },
        "id": "IsGjKseN3XFh"
      },
      "outputs": [],
      "source": [
        "entity=\"vitaliy-sharandin-org\"\n",
        "project_name=\"Psy-AI\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
        "\n",
        "model_trained_checkpoint = 'llama3-trained'\n",
        "registry_model_name = \"psy-ai-model\"\n",
        "\n",
        "def bleu_rouge_f1_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "  labels = [[idx for idx in label if idx != -100] for label in labels]\n",
        "  predictions = [[idx for idx in prediction if idx != -100] for prediction in predictions]\n",
        "\n",
        "  decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  bleu = load(\"bleu\")\n",
        "  bleu_results = bleu.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "\n",
        "  rouge = load('rouge')\n",
        "  rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "\n",
        "  f1 = 2 * (bleu_results['bleu'] * rouge_results['rouge1']) / (bleu_results['bleu'] + rouge_results['rouge1'])\n",
        "\n",
        "  scores = {\n",
        "        \"bleu\": bleu_results[\"bleu\"],\n",
        "        \"rouge1\": rouge_results[\"rouge1\"],\n",
        "        \"rouge2\": rouge_results[\"rouge2\"],\n",
        "        \"rougeL\": rouge_results[\"rougeL\"],\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "  wandb.log(scores)\n",
        "\n",
        "  return scores\n",
        "\n",
        "def fine_tune(model, tokenizer, train_dataset, eval_dataset, metrics_func, only_evaluate=False):\n",
        "\n",
        "  supervised_finetuning_trainer = SFTTrainer(model=model,\n",
        "                                            train_dataset=train_dataset,\n",
        "                                            eval_dataset=eval_dataset,\n",
        "                                            args=TrainingArguments(\n",
        "                                                output_dir=\"./training_results\",\n",
        "                                                report_to=\"wandb\",\n",
        "                                                per_device_train_batch_size=8,\n",
        "                                                per_device_eval_batch_size=1,\n",
        "                                                gradient_accumulation_steps=2,\n",
        "                                                gradient_checkpointing=True,\n",
        "                                                ddp_find_unused_parameters=False,\n",
        "                                                optim=\"paged_adamw_8bit\",\n",
        "                                                save_steps=1000,\n",
        "                                                logging_steps=30,\n",
        "                                                learning_rate=2e-4,\n",
        "                                                weight_decay=0.001,\n",
        "                                                fp16=False,\n",
        "                                                bf16=False,\n",
        "                                                max_grad_norm=0.3,\n",
        "                                                max_steps=-1,\n",
        "                                                warmup_ratio=0.3,\n",
        "                                                group_by_length=True,\n",
        "                                                lr_scheduler_type=\"constant\"\n",
        "                                            ),\n",
        "                                            dataset_text_field=\"text\",\n",
        "                                            max_seq_length=2048,\n",
        "                                            compute_metrics=metrics_func,\n",
        "                                            data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False))\n",
        "\n",
        "  if only_evaluate:\n",
        "    return supervised_finetuning_trainer.evaluate()\n",
        "\n",
        "  else:\n",
        "    with wandb.init(entity=entity, project=project_name) as run:\n",
        "      supervised_finetuning_trainer.train()\n",
        "      supervised_finetuning_trainer.model.save_pretrained(model_trained_checkpoint)\n",
        "      tokenizer.save_pretrained(model_trained_checkpoint)\n",
        "      run.link_model(path=model_trained_checkpoint, registered_model_name={entity}/{project_name}/{registry_model_name})\n",
        "\n",
        "      wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d6b57539-d1c2-497d-a1dc-b8401c480792",
          "showTitle": false,
          "title": ""
        },
        "id": "irSVYaRU4op0"
      },
      "source": [
        "## Evaluating base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "65e93ddb-c8c5-4744-9188-9f4231580f5d",
          "showTitle": false,
          "title": ""
        },
        "id": "NBhgMjWAE_6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "bb82b50e917f422aa684a91cd0c6c778",
            "6388885966004b74bcf109f88ea44eee",
            "6621dd4210cc4997925c324015b977e9",
            "86ed112ec13d4a30a41c803efd6a7c21",
            "fbaf167a7f8b4c3980637f894cc675cc",
            "adb323ab5a8b407c9f092467bb8839f7",
            "b410f869cde040f7a9f435893163dd87",
            "3fb9916cdcf14dceb302e0bc8cf0bbeb",
            "abd69069c834453da9ce02d5a3e97930",
            "d4d4941881ae4c7f88a9eef8bebd0bec",
            "7f2fcba8ed6e400d9d3c454b5546b7fe",
            "0d826ad7039045e09787ffb63e24e0da",
            "ef16d45e292f46788e11d34c992203c2",
            "fa5e4d54ccf048dc9268423f2b9ac630",
            "827ad0c3b9da4f1ab46ed2327554dfc0",
            "9bf53fc672a34457b26cb38f22f9df4e",
            "082a0dbbe6f84679bcf0865db4b9bba0",
            "0e7f57086d214b969700f04d09df8a63",
            "3993d8dc07db41b8af2e9f20d46869d6",
            "1b64dbff83db4836a14bc6259eae0ecb",
            "3f46a36f6cfe44c589d4ca26a9b2c5cd",
            "190571210706448fab153d244894dcd4"
          ]
        },
        "outputId": "028508f1-024d-4dee-cc0b-d36594619449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb82b50e917f422aa684a91cd0c6c778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d826ad7039045e09787ffb63e24e0da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49/51 00:42 < 00:01, 1.12 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.63 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.58 GiB is free. Process 348403 has 12.17 GiB memory in use. Of the allocated memory 10.11 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1e4423f02c80>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-9b3ea7f61d3a>\u001b[0m in \u001b[0;36mfine_tune\u001b[0;34m(model, tokenizer, train_dataset, eval_dataset, metrics_func, only_evaluate)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0monly_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msupervised_finetuning_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3467\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3468\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3668\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3669\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3670\u001b[0;31m                 \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3671\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3672\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         return type(tensors)(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Now let's fill the result tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.63 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.58 GiB is free. Process 348403 has 12.17 GiB memory in use. Of the allocated memory 10.11 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    \"model\": base_training_model,\n",
        "    \"tokenizer\": tokenizer,\n",
        "    \"train_dataset\": formatted_depression_dataset_train,\n",
        "    \"eval_dataset\": formatted_depression_dataset_train,\n",
        "    \"metrics_func\": bleu_rouge_f1_metrics,\n",
        "    \"only_evaluate\": True\n",
        "}\n",
        "\n",
        "fine_tune(**params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2de1a8c3-6a52-4ddd-a484-1a385fa79bb5",
          "showTitle": false,
          "title": ""
        },
        "id": "e199cTOsNrgV"
      },
      "source": [
        "Evaluation metrics are quite low before training.\n",
        "\n",
        "Let's train the model and see how metrics and responses change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "25219d74-a6c5-4d2e-8874-06a8e89138c8",
          "showTitle": false,
          "title": ""
        },
        "id": "ernG2FcS4tuG"
      },
      "source": [
        "## Fine-tuning base model and registering it to WanDB model registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "adf01b50-df15-48b8-8186-7e40783aca54",
          "showTitle": false,
          "title": ""
        },
        "id": "Z8RswZBWxqfR"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"model\": base_training_model,\n",
        "    \"tokenizer\": tokenizer,\n",
        "    \"train_dataset\": formatted_depression_dataset_train,\n",
        "    \"eval_dataset\": formatted_depression_dataset_train,\n",
        "    \"metrics_func\": bleu_rouge_f1_metrics\n",
        "}\n",
        "\n",
        "fine_tune(**params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "342f7272-6626-4d53-af94-cb67fd845693",
          "showTitle": false,
          "title": ""
        },
        "id": "x0agS0CmSh6a"
      },
      "source": [
        "## Loading and evaluating model from Wandb model registry"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "downloaded_model_path = run.use_model(name=f\"{entity}/{project_name}/{registry_model_name}:latest\")"
      ],
      "metadata": {
        "id": "WjXSeKzQUuJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(downloaded_model_path, device_map=\"auto\", quantization_config=BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "  ))"
      ],
      "metadata": {
        "id": "NRBYVqR_cQr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"model\": model,\n",
        "    \"tokenizer\": tokenizer,\n",
        "    \"train_dataset\": formatted_depression_dataset_train,\n",
        "    \"eval_dataset\": formatted_depression_dataset_train,\n",
        "    \"metrics_func\": bleu_rouge_f1_metrics,\n",
        "    \"only_evaluate\": True\n",
        "}\n",
        "\n",
        "fine_tune(**params)"
      ],
      "metadata": {
        "id": "eqJJRhOqfJxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5e7e87ec-ba40-4a48-bfee-d8fd6dda6111",
          "showTitle": false,
          "title": ""
        },
        "id": "C9agpWsaZUL0"
      },
      "source": [
        "# Saving fine-tuned model with adapters to Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45d02fc0-076f-4371-83d6-bd8d86f3c400",
          "showTitle": false,
          "title": ""
        },
        "id": "baJM5WLITraq"
      },
      "source": [
        "Now we are able to merge our model with saved peft adapters and push it to Hugging Face repo.\n",
        "\n",
        "We have to launch this cell separately, as VRAM will be filled up to fullest point when we merge adapters with original model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "04708f94-9b04-4b2a-9703-79f855067ce9",
          "showTitle": false,
          "title": ""
        },
        "id": "20saoYRljDzV"
      },
      "outputs": [],
      "source": [
        "# tuned_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "#     model_trained_checkpoint,\n",
        "#     low_cpu_mem_usage=True,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     device_map = {\"\": 0}\n",
        "# )\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_trained_checkpoint)\n",
        "\n",
        "# merged_model = tuned_model.merge_and_unload()\n",
        "\n",
        "# merged_model.save_pretrained(model_merged, safe_serialization=True)\n",
        "# tokenizer.save_pretrained(model_merged)\n",
        "\n",
        "# mlflow.register_model(model_uri=model_merged, name=\"psy-ai\")\n",
        "\n",
        "# # token=''\n",
        "# # merged_model.push_to_hub(\"vitaliy-sharandin/wiseai\", token=token)\n",
        "# # tokenizer.push_to_hub(\"vitaliy-sharandin/wiseai\", token=token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "aed40ac0-70f1-460a-a97c-1ba0e689f90b",
          "showTitle": false,
          "title": ""
        },
        "id": "afAivp4AEmgr"
      },
      "source": [
        "# Gradio demo in Hugging Face Spaces\n",
        "\n",
        "https://huggingface.co/spaces/vitaliy-sharandin/WiseAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cc797601-6ed6-435e-aea0-7f82acfc1e24",
          "showTitle": false,
          "title": ""
        },
        "id": "L1kfrRdm6XDS"
      },
      "source": [
        "## Local launch\n",
        "Requirements:\n",
        "* Choose free T4 GPU in Colab environment settings\n",
        "* Run `pip install` and `imports` cells at the beginning before launching Gradio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8f1b143c-8214-4b1f-99ba-bc655efe2f4a",
          "showTitle": false,
          "title": ""
        },
        "id": "TbFojGP4s2VZ"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "      'vitaliy-sharandin/wiseai',\n",
        "      load_in_8bit=True,\n",
        "      device_map = {\"\": 0}\n",
        "  )\n",
        "tokenizer = AutoTokenizer.from_pretrained('vitaliy-sharandin/wiseai')\n",
        "\n",
        "pipe = pipeline('text-generation', model=model,tokenizer=tokenizer)\n",
        "\n",
        "def generate_text(instruction, input):\n",
        "  if not instruction.strip():\n",
        "    return str('The instruction field is required.')\n",
        "\n",
        "  if instruction.strip() and input.strip():\n",
        "    input_prompt = (f\"Below is an instruction that describes a task. \"\n",
        "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      \"### Instruction:\\n\"\n",
        "      f\"{instruction}\\n\\n\"\n",
        "      \"### Input:\\n\"\n",
        "      f\"{input}\\n\\n\"\n",
        "      f\"### Response: \\n\")\n",
        "  else :\n",
        "    input_prompt = (f\"Below is an instruction that describes a task. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n\"\n",
        "        f\"{instruction}\\n\\n\"\n",
        "        f\"### Response: \\n\")\n",
        "  result = pipe(input_prompt, max_length=200, top_p=0.9, temperature=0.9, num_return_sequences=1, return_full_text=False)[0]['generated_text']\n",
        "  return result[:str(result).find(\"###\")]\n",
        "\n",
        "iface = gr.Interface(fn=generate_text, inputs=[gr.Textbox(label=\"Instruction\"),\n",
        "                                               gr.Textbox(label=\"Additional Input\")],\n",
        "                     outputs=gr.Textbox(label=\"Response\"))\n",
        "iface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "psy_ai_mlflow_tracking_deployment",
      "widgets": {}
    },
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d86ed2157b8d4937be3bca87d94a791a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e4fc7b4a62545b1b9f7a92aee5d4f1d",
              "IPY_MODEL_5568f5e9f99c46799bbfd304841cc5ee",
              "IPY_MODEL_8c7726b2c6f3411a99c715db4283d75f"
            ],
            "layout": "IPY_MODEL_9e7306c2036547f680a951e279f3cad3"
          }
        },
        "9e4fc7b4a62545b1b9f7a92aee5d4f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b780273471f144a48cea7b2d6ab7eedd",
            "placeholder": "",
            "style": "IPY_MODEL_a48c9c3c9a604f0ca7f07bffdb395668",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "5568f5e9f99c46799bbfd304841cc5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb16bf91be544729e49ee2c1a03762d",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9000a1453d64757b87d1939d933138e",
            "value": 4
          }
        },
        "8c7726b2c6f3411a99c715db4283d75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8741ad72690a4c31b6cec6fa57234954",
            "placeholder": "",
            "style": "IPY_MODEL_519a41fb203242e7ba381f595046161e",
            "value": "4/4[01:23&lt;00:00,17.79s/it]"
          }
        },
        "9e7306c2036547f680a951e279f3cad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b780273471f144a48cea7b2d6ab7eedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48c9c3c9a604f0ca7f07bffdb395668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb16bf91be544729e49ee2c1a03762d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9000a1453d64757b87d1939d933138e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8741ad72690a4c31b6cec6fa57234954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519a41fb203242e7ba381f595046161e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb82b50e917f422aa684a91cd0c6c778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6388885966004b74bcf109f88ea44eee",
              "IPY_MODEL_6621dd4210cc4997925c324015b977e9",
              "IPY_MODEL_86ed112ec13d4a30a41c803efd6a7c21"
            ],
            "layout": "IPY_MODEL_fbaf167a7f8b4c3980637f894cc675cc"
          }
        },
        "6388885966004b74bcf109f88ea44eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adb323ab5a8b407c9f092467bb8839f7",
            "placeholder": "",
            "style": "IPY_MODEL_b410f869cde040f7a9f435893163dd87",
            "value": "Map:100%"
          }
        },
        "6621dd4210cc4997925c324015b977e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb9916cdcf14dceb302e0bc8cf0bbeb",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abd69069c834453da9ce02d5a3e97930",
            "value": 51
          }
        },
        "86ed112ec13d4a30a41c803efd6a7c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d4941881ae4c7f88a9eef8bebd0bec",
            "placeholder": "",
            "style": "IPY_MODEL_7f2fcba8ed6e400d9d3c454b5546b7fe",
            "value": "51/51[00:00&lt;00:00,885.65examples/s]"
          }
        },
        "fbaf167a7f8b4c3980637f894cc675cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb323ab5a8b407c9f092467bb8839f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b410f869cde040f7a9f435893163dd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb9916cdcf14dceb302e0bc8cf0bbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd69069c834453da9ce02d5a3e97930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4d4941881ae4c7f88a9eef8bebd0bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2fcba8ed6e400d9d3c454b5546b7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d826ad7039045e09787ffb63e24e0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef16d45e292f46788e11d34c992203c2",
              "IPY_MODEL_fa5e4d54ccf048dc9268423f2b9ac630",
              "IPY_MODEL_827ad0c3b9da4f1ab46ed2327554dfc0"
            ],
            "layout": "IPY_MODEL_9bf53fc672a34457b26cb38f22f9df4e"
          }
        },
        "ef16d45e292f46788e11d34c992203c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082a0dbbe6f84679bcf0865db4b9bba0",
            "placeholder": "",
            "style": "IPY_MODEL_0e7f57086d214b969700f04d09df8a63",
            "value": "Map:100%"
          }
        },
        "fa5e4d54ccf048dc9268423f2b9ac630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3993d8dc07db41b8af2e9f20d46869d6",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b64dbff83db4836a14bc6259eae0ecb",
            "value": 51
          }
        },
        "827ad0c3b9da4f1ab46ed2327554dfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f46a36f6cfe44c589d4ca26a9b2c5cd",
            "placeholder": "",
            "style": "IPY_MODEL_190571210706448fab153d244894dcd4",
            "value": "51/51[00:00&lt;00:00,976.19examples/s]"
          }
        },
        "9bf53fc672a34457b26cb38f22f9df4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082a0dbbe6f84679bcf0865db4b9bba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7f57086d214b969700f04d09df8a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3993d8dc07db41b8af2e9f20d46869d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b64dbff83db4836a14bc6259eae0ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f46a36f6cfe44c589d4ca26a9b2c5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190571210706448fab153d244894dcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}